{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b965b6-f313-4bfb-8ee9-fa3985837af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/1.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.8 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-25.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade tensorflow==2.19.0\n",
    "!pip install seaborn\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf114ea-0827-47d2-bb57-55f9f97fec6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#####IMPORTS#####\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#####IMPORTS#####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "#####IMPORT DATA AND CLEANING OF DATA#####\n",
    "#data = pd.read_csv(\"diabetes_binary_5050split_health_indicators_BRFSS2015.csv\", on_bad_lines=\"skip\")\n",
    "data0 = pd.read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\", on_bad_lines=\"skip\")\n",
    "\n",
    "correlation_matrix = data0.corr()\n",
    "corr_with_outcome = correlation_matrix['Diabetes_binary']\n",
    "best_features = corr_with_outcome.drop('Diabetes_binary').abs().sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "rng_seed = 3\n",
    "np.random.seed(rng_seed)\n",
    "random.seed(rng_seed)\n",
    "tf.random.set_seed(rng_seed)\n",
    "\n",
    "\n",
    "X = data0[best_features]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = data0['Diabetes_binary']\n",
    "#data0.drop('Diabetes_binary', axis=1)\n",
    "XTRAIN, XTEST, YTRAIN, YTEST = train_test_split(X[:15000,:], Y[:15000], test_size=0.2,random_state=rng_seed) #trimmed down to first 25k data points\n",
    "XVALID = X[-1:-10000:-1,:] #using the last 10k data points for validation data to decide which model is\n",
    "YVALID = Y[-1:-10000:-1]   #performing the best to make our final selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de597cde-0b40-4c41-858f-a50319b463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-09 00:28:17.606296: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.4659 - val_accuracy: 0.8375 - val_loss: 0.3672\n",
      "Epoch 2/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.3679 - val_accuracy: 0.8400 - val_loss: 0.3641\n",
      "Epoch 3/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3651 - val_accuracy: 0.8413 - val_loss: 0.3630\n",
      "Epoch 4/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8421 - loss: 0.3637 - val_accuracy: 0.8392 - val_loss: 0.3626\n",
      "Epoch 5/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3628 - val_accuracy: 0.8383 - val_loss: 0.3622\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.1901 - mse: 0.1901 - val_accuracy: 0.8417 - val_loss: 0.1148 - val_mse: 0.1148\n",
      "Epoch 2/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.1160 - mse: 0.1160 - val_accuracy: 0.8408 - val_loss: 0.1136 - val_mse: 0.1136\n",
      "Epoch 3/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.1144 - mse: 0.1144 - val_accuracy: 0.8404 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 4/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.1135 - mse: 0.1135 - val_accuracy: 0.8413 - val_loss: 0.1136 - val_mse: 0.1136\n",
      "Epoch 5/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.1133 - mse: 0.1133 - val_accuracy: 0.8404 - val_loss: 0.1136 - val_mse: 0.1136\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.1420 - mse: 0.1420 - val_accuracy: 0.8375 - val_loss: 0.1176 - val_mse: 0.1176\n",
      "Epoch 2/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.1177 - mse: 0.1177 - val_accuracy: 0.8375 - val_loss: 0.1146 - val_mse: 0.1146\n",
      "Epoch 3/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.1157 - mse: 0.1157 - val_accuracy: 0.8379 - val_loss: 0.1142 - val_mse: 0.1142\n",
      "Epoch 4/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.1151 - mse: 0.1151 - val_accuracy: 0.8367 - val_loss: 0.1139 - val_mse: 0.1139\n",
      "Epoch 5/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.1147 - mse: 0.1147 - val_accuracy: 0.8388 - val_loss: 0.1137 - val_mse: 0.1137\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.1430 - mse: 0.1430 - val_accuracy: 0.8375 - val_loss: 0.1154 - val_mse: 0.1154\n",
      "Epoch 2/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.1147 - mse: 0.1147 - val_accuracy: 0.8413 - val_loss: 0.1146 - val_mse: 0.1146\n",
      "Epoch 3/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.1141 - mse: 0.1141 - val_accuracy: 0.8404 - val_loss: 0.1143 - val_mse: 0.1143\n",
      "Epoch 4/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.1137 - mse: 0.1137 - val_accuracy: 0.8400 - val_loss: 0.1142 - val_mse: 0.1142\n",
      "Epoch 5/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.1136 - mse: 0.1136 - val_accuracy: 0.8396 - val_loss: 0.1141 - val_mse: 0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.1248 - mse: 0.1248 - val_accuracy: 0.8300 - val_loss: 0.1170 - val_mse: 0.1170\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.1741 - val_accuracy: 0.8400 - val_loss: 0.1190\n",
      "Epoch 2/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.1165 - val_accuracy: 0.8400 - val_loss: 0.1163\n",
      "Epoch 3/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.1147 - val_accuracy: 0.8383 - val_loss: 0.1153\n",
      "Epoch 4/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.1139 - val_accuracy: 0.8379 - val_loss: 0.1152\n",
      "Epoch 5/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.1136 - val_accuracy: 0.8379 - val_loss: 0.1149\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.1610 - val_accuracy: 0.8358 - val_loss: 0.1170\n",
      "Epoch 2/5\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.1150 - val_accuracy: 0.8363 - val_loss: 0.1163\n",
      "Epoch 3/5\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.1143 - val_accuracy: 0.8363 - val_loss: 0.1156\n",
      "Epoch 4/5\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.1138 - val_accuracy: 0.8367 - val_loss: 0.1153\n",
      "Epoch 5/5\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8455 - loss: 0.1135 - val_accuracy: 0.8358 - val_loss: 0.1150\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.1347 - val_accuracy: 0.8404 - val_loss: 0.1145\n",
      "Epoch 2/5\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8420 - loss: 0.1146 - val_accuracy: 0.8388 - val_loss: 0.1145\n",
      "Epoch 3/5\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: 0.1141 - val_accuracy: 0.8371 - val_loss: 0.1145\n",
      "Epoch 4/5\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8439 - loss: 0.1136 - val_accuracy: 0.8383 - val_loss: 0.1148\n",
      "Epoch 5/5\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.1135 - val_accuracy: 0.8392 - val_loss: 0.1147\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2558 - loss: 0.3466 - val_accuracy: 0.8375 - val_loss: 0.1808\n",
      "Epoch 2/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.1682 - val_accuracy: 0.8375 - val_loss: 0.1458\n",
      "Epoch 3/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.1451 - val_accuracy: 0.8375 - val_loss: 0.1391\n",
      "Epoch 4/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.1403 - val_accuracy: 0.8375 - val_loss: 0.1372\n",
      "Epoch 5/5\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.1389 - val_accuracy: 0.8375 - val_loss: 0.1365\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8288 - loss: 0.3846 - val_accuracy: 0.8375 - val_loss: 0.3626\n",
      "Epoch 2/3\n",
      "\u001b[1m4789/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3672"
     ]
    }
   ],
   "source": [
    "############  [NEURAL NETWORKS]  #############\n",
    "\n",
    "# === MODEL 1 ===\n",
    "neural_model1 = Sequential()\n",
    "neural_model1.add(Dense(128, activation='relu', input_dim = 5))\n",
    "neural_model1.add(Dense(64, activation='sigmoid'))\n",
    "neural_model1.add(Dense(48, activation='relu'))\n",
    "neural_model1.add(Dense(32, activation='sigmoid'))\n",
    "neural_model1.add(Dense(16, activation='relu'))\n",
    "neural_model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = neural_model1.fit(XTRAIN, YTRAIN,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# === MODEL 2 ===\n",
    "\n",
    "neural_model2 = Sequential()\n",
    "neural_model2.add(Dense(20, activation='relu', input_dim = 5))\n",
    "neural_model2.add(Dense(10, activation='relu'))\n",
    "neural_model2.add(Dense(5, activation='relu'))\n",
    "neural_model2.add(Dense(1))\n",
    "\n",
    "neural_model2.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy','mse'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history2 = neural_model2.fit(XTRAIN, YTRAIN,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# === MODEL 3 ===\n",
    "\n",
    "neural_model3 = Sequential()\n",
    "neural_model3.add(Dense(20, activation='sigmoid', input_dim = 5))\n",
    "neural_model3.add(Dense(10, activation='sigmoid'))\n",
    "neural_model3.add(Dense(5, activation='sigmoid'))\n",
    "neural_model3.add(Dense(1))\n",
    "\n",
    "neural_model3.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy','mse'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history3 = neural_model3.fit(XTRAIN, YTRAIN,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# === MODEL 4 ===\n",
    "\n",
    "neural_model4 = Sequential()\n",
    "neural_model4.add(Dense(128, activation='relu', input_dim = 5))\n",
    "neural_model4.add(Dense(64, activation='sigmoid'))\n",
    "neural_model4.add(Dense(48, activation='relu'))\n",
    "neural_model4.add(Dense(32, activation='sigmoid'))\n",
    "neural_model4.add(Dense(16, activation='relu'))\n",
    "neural_model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model4.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy','mse'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = neural_model4.fit(XTRAIN, YTRAIN,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# === MODEL 5 ===\n",
    "\n",
    "neural_model5 = Sequential()\n",
    "neural_model5.add(Dense(256, activation='sigmoid', input_dim = 5))\n",
    "neural_model5.add(Dense(128, activation='sigmoid'))\n",
    "neural_model5.add(Dense(64, activation='relu'))\n",
    "neural_model5.add(Dense(32, activation='relu'))\n",
    "neural_model5.add(Dense(16, activation='sigmoid'))\n",
    "neural_model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model5.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy','mse'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = neural_model5.fit(XTRAIN, YTRAIN,\n",
    "                    batch_size=1,\n",
    "                    epochs=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# === MODEL 6 ===\n",
    "neural_model6 = Sequential()\n",
    "neural_model6.add(Dense(128, activation='relu', input_dim=5))\n",
    "neural_model6.add(Dense(64, activation='relu'))\n",
    "neural_model6.add(Dense(32, activation='sigmoid'))\n",
    "neural_model6.add(Dense(16, activation='relu'))\n",
    "neural_model6.add(Dense(8, activation='sigmoid'))\n",
    "neural_model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model6.compile(optimizer='adam',\n",
    "                      loss='mse',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "early_stopping6 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history6 = neural_model6.fit(XTRAIN, YTRAIN,\n",
    "                              batch_size=8,\n",
    "                              epochs=5,\n",
    "                              validation_split=0.2,\n",
    "                              callbacks=[early_stopping6])\n",
    "\n",
    "# === MODEL 7 ===\n",
    "neural_model7 = Sequential()\n",
    "neural_model7.add(Dense(64, activation='tanh', input_dim=5))\n",
    "neural_model7.add(Dense(64, activation='relu'))\n",
    "neural_model7.add(Dense(32, activation='relu'))\n",
    "neural_model7.add(Dense(16, activation='sigmoid'))\n",
    "neural_model7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model7.compile(optimizer='rmsprop',\n",
    "                      loss='mse',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "early_stopping7 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history7 = neural_model7.fit(XTRAIN, YTRAIN,\n",
    "                              batch_size=16,\n",
    "                              epochs=5,\n",
    "                              validation_split=0.2,\n",
    "                              callbacks=[early_stopping7])\n",
    "\n",
    "# === MODEL 8 ===\n",
    "neural_model8 = Sequential()\n",
    "neural_model8.add(Dense(512, activation='relu', input_dim=5))\n",
    "neural_model8.add(Dense(256, activation='relu'))\n",
    "neural_model8.add(Dense(128, activation='sigmoid'))\n",
    "neural_model8.add(Dense(64, activation='relu'))\n",
    "neural_model8.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model8.compile(optimizer='adam',\n",
    "                      loss='mse',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "early_stopping8 = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "history8 = neural_model8.fit(XTRAIN, YTRAIN,\n",
    "                              batch_size=64,\n",
    "                              epochs=5,\n",
    "                              validation_split=0.2,\n",
    "                              callbacks=[early_stopping8])\n",
    "\n",
    "# === MODEL 9 ===\n",
    "neural_model9 = Sequential()\n",
    "neural_model9.add(Dense(100, activation='relu', input_dim=5))\n",
    "neural_model9.add(Dense(50, activation='relu'))\n",
    "neural_model9.add(Dense(25, activation='sigmoid'))\n",
    "neural_model9.add(Dense(12, activation='relu'))\n",
    "neural_model9.add(Dense(6, activation='sigmoid'))\n",
    "neural_model9.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model9.compile(optimizer='sgd',\n",
    "                      loss='mse',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "early_stopping9 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history9 = neural_model9.fit(XTRAIN, YTRAIN,\n",
    "                              batch_size=32,\n",
    "                              epochs=5,\n",
    "                              validation_split=0.2,\n",
    "                              callbacks=[early_stopping9])\n",
    "\n",
    "# === MODEL 10 ===\n",
    "neural_model10 = Sequential()\n",
    "neural_model10.add(Dense(300, activation='relu', input_dim=5))\n",
    "neural_model10.add(Dense(150, activation='sigmoid'))\n",
    "neural_model10.add(Dense(75, activation='relu'))\n",
    "neural_model10.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "neural_model10.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "early_stopping10 = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history10 = neural_model10.fit(XTRAIN, YTRAIN,\n",
    "                                batch_size=2,\n",
    "                                epochs=3,\n",
    "                                validation_split=0.2,\n",
    "                                callbacks=[early_stopping10])\n",
    "\n",
    "######### COMPILE NEURAL NETWORKS ##########\n",
    "NETWORK_NAMES = ['Neural Network Model 1','Neural Network Model 2','Neural Network Model 3','Neural Network Model 4','Neural Network Model 5','Neural Network Model 6','Neural Network Model 7','Neural Network Model 8','Neural Network Model 9','Neural Network Model 10']\n",
    "NETWORKS = [neural_model1, neural_model2, neural_model3,neural_model4,neural_model5,neural_model6,neural_model7,neural_model8,neural_model9,neural_model10,]\n",
    "neural_network_accuracies = np.empty(len(NETWORKS), dtype=float)\n",
    "######### NEURAL NETWORK ACCURACY ##########\n",
    "for net_idx in range(len(NETWORKS)):\n",
    "    neural_network_predictions = NETWORKS[net_idx].predict(XVALID)\n",
    "    predicted_outcome = np.zeros(len(neural_network_predictions), dtype=float)\n",
    "    for pred_idx in range(len(neural_network_predictions)):\n",
    "      if neural_network_predictions[pred_idx] > 0.5:\n",
    "        predicted_outcome[pred_idx] = 1\n",
    "      else:\n",
    "        predicted_outcome[pred_idx] = 0\n",
    "    neural_network_accuracies[net_idx] = np.mean(predicted_outcome==YVALID)\n",
    "neural_network_best_accuracy = np.max(neural_network_accuracies)\n",
    "neural_network_best_model = NETWORKS[np.argmax(neural_network_accuracies)]\n",
    "print(f'Neural Network Best Accuracy: {neural_network_best_accuracy} Neural Network Best Model: {NETWORK_NAMES[np.argmax(neural_network_accuracies)]}')\n",
    "\n",
    "\n",
    "neural_network_model_names = [f'NN Model {i+1}' for i in range(len(NETWORKS))]\n",
    "\n",
    "\n",
    "neural_network_data =  list(zip(neural_network_model_names, neural_network_accuracies))\n",
    "\n",
    "\n",
    "neural_network_headers = [\"Model Name\", \"Accuracy (%)\"]\n",
    "\n",
    "neural_network_table = tabulate(neural_network_data, headers=neural_network_headers, tablefmt=\"github\")\n",
    "print(neural_network_table)\n",
    "\n",
    "\n",
    "# Plot a bar graph comparing neural network model accuracies\n",
    "plt.figure(figsize=(16, 6))\n",
    "bars = plt.bar(NETWORK_NAMES, neural_network_accuracies * 100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Highlight the best model in a different color\n",
    "best_idx = np.argmax(neural_network_accuracies)\n",
    "bars[best_idx].set_color('orange')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Neural Network Models', fontsize=12)\n",
    "plt.ylabel('Validation Accuracy (%)', fontsize=12)\n",
    "plt.title('Comparison of Neural Network Models by Validation Accuracy', fontsize=14)\n",
    "plt.ylim(80, 90)\n",
    "\n",
    "# Annotate bars with accuracy values\n",
    "for bar, acc in zip(bars, neural_network_accuracies * 100):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{acc:.2f}%', ha='center', fontsize=8, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf449e0-4cc4-4d01-af9d-da530070837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############  [ADABOOTS]  #############\n",
    "estimator_start = 1\n",
    "estimator_end = 50\n",
    "idx_start = 0\n",
    "idx_end = estimator_end - estimator_start\n",
    "num_adas = estimator_end - estimator_start\n",
    "\n",
    "adaboost_accuracies = np.empty(estimator_end - estimator_start, dtype=float)\n",
    "adaboost_models = np.empty(estimator_end - estimator_start, dtype='object')\n",
    "\n",
    "for i in range(idx_start,idx_end):  # i from start to num_adas\n",
    "    adaboost_models[i] = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2,random_state=rng_seed),n_estimators=(estimator_start+i),random_state=rng_seed)\n",
    "    adaboost_models[i].fit(XTRAIN, YTRAIN)\n",
    "    adaboost_accuracies[i] = np.mean(adaboost_models[i].predict(XVALID) == YVALID)\n",
    "\n",
    "adaboost_best_accuracy = np.max(adaboost_accuracies)\n",
    "adaboost_best_model = adaboost_models[np.argmax(adaboost_accuracies)]\n",
    "\n",
    "plt.plot(range(estimator_start, estimator_end), adaboost_accuracies)\n",
    "plt.plot(np.argmax(adaboost_accuracies)+estimator_start, adaboost_accuracies[np.argmax(adaboost_accuracies)], 'ro')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Number of Estimators')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "adaboost_model_names = [f'Adaboost Model {i+1}' for i in range(len(adaboost_models))]\n",
    "\n",
    "adaboost_data =  list(zip(adaboost_model_names, adaboost_accuracies))\n",
    "\n",
    "\n",
    "adaboost_headers = [\"Model Name\", \"Accuracy (%)\"]\n",
    "\n",
    "adaboost_table = tabulate(adaboost_data, headers=adaboost_headers, tablefmt=\"github\")\n",
    "print(adaboost_table)\n",
    "\n",
    "\n",
    "\n",
    "# Plot a bar graph of the accuracies for each model (number of estimators)\n",
    "plt.figure(figsize=(16, 6))\n",
    "bars = plt.bar(adaboost_model_names, adaboost_accuracies * 100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Highlight the best model in a different color\n",
    "best_idx = np.argmax(adaboost_accuracies)\n",
    "bars[best_idx].set_color('orange')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Adaboost Models', fontsize=12)\n",
    "plt.ylabel('Validation Accuracy (%)', fontsize=12)\n",
    "plt.title('Comparison of Adaboost Models by Validation Accuracy', fontsize=14)\n",
    "plt.ylim(80, 90)\n",
    "\n",
    "# Annotate bars with accuracy values\n",
    "for bar, acc in zip(bars, adaboost_accuracies * 100):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{acc:.2f}%', ha='center', fontsize=8,rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c197d-22c3-49c2-a052-98ece5a4de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRA LOGISTIC REGRESSION MODELS WITH ACCURACIES ###\n",
    "logreg_model_1 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l2', solver='liblinear',random_state=rng_seed))])\n",
    "logreg_model_1.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 1 Accuracy:\", logreg_model_1.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_2 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga', max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_2.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 2 Accuracy:\", logreg_model_2.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_3 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty=None, solver='saga', max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_3.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 3 Accuracy:\", logreg_model_3.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_4 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l2', solver='lbfgs', C=0.1,random_state=rng_seed))])\n",
    "logreg_model_4.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 4 Accuracy:\", logreg_model_4.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_5 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l2', solver='lbfgs', C=10,random_state=rng_seed))])\n",
    "logreg_model_5.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 5 Accuracy:\", logreg_model_5.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_6 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l2', solver='saga', multi_class='multinomial', max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_6.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 6 Accuracy:\", logreg_model_6.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_7 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l2', solver='liblinear',random_state=rng_seed))])\n",
    "logreg_model_7.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 7 Accuracy:\", logreg_model_7.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_8 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l1', solver='saga', max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_8.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 8 Accuracy:\", logreg_model_8.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_9 = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('logreg', LogisticRegression(penalty='l2', solver='newton-cg',random_state=rng_seed))])\n",
    "logreg_model_9.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 9 Accuracy:\", logreg_model_9.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_10 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='saga', max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_10.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 10 Accuracy:\", logreg_model_10.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_11 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='lbfgs',random_state=rng_seed))])\n",
    "logreg_model_11.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 11 Accuracy:\", logreg_model_11.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_12 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='liblinear', C=0.01,random_state=rng_seed))])\n",
    "logreg_model_12.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 12 Accuracy:\", logreg_model_12.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_13 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='liblinear', C=100,random_state=rng_seed))])\n",
    "logreg_model_13.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 13 Accuracy:\", logreg_model_13.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_14 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l1', solver='liblinear', C=0.5,random_state=rng_seed))])\n",
    "logreg_model_14.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 14 Accuracy:\", logreg_model_14.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_15 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l1', solver='liblinear', C=2,random_state=rng_seed))])\n",
    "logreg_model_15.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 15 Accuracy:\", logreg_model_15.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_16 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='newton-cg', C=0.5,random_state=rng_seed))])\n",
    "logreg_model_16.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 16 Accuracy:\", logreg_model_16.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_17 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='saga', C=0.5, max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_17.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 17 Accuracy:\", logreg_model_17.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_18 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.2, max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_18.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 18 Accuracy:\", logreg_model_18.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_19 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.8, max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_19.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 19 Accuracy:\", logreg_model_19.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_20 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty=None, solver='saga', max_iter=200,random_state=rng_seed))])\n",
    "logreg_model_20.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 20 Accuracy:\", logreg_model_20.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_21 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200,random_state=rng_seed))])\n",
    "logreg_model_21.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 21 Accuracy:\", logreg_model_21.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_22 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='saga', max_iter=200,random_state=rng_seed))])\n",
    "logreg_model_22.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 22 Accuracy:\", logreg_model_22.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_23 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l1', solver='saga', max_iter=200,random_state=rng_seed))])\n",
    "logreg_model_23.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 23 Accuracy:\", logreg_model_23.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_24 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l1', solver='liblinear', C=0.1,random_state=rng_seed))])\n",
    "logreg_model_24.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 24 Accuracy:\", logreg_model_24.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_25 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l1', solver='liblinear', C=10,random_state=rng_seed))])\n",
    "logreg_model_25.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 25 Accuracy:\", logreg_model_25.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_26 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='lbfgs', multi_class='ovr',random_state=rng_seed))])\n",
    "logreg_model_26.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 26 Accuracy:\", logreg_model_26.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_27 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='lbfgs', multi_class='multinomial',random_state=rng_seed))])\n",
    "logreg_model_27.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 27 Accuracy:\", logreg_model_27.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_28 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l2', solver='saga', multi_class='ovr', max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_28.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 28 Accuracy:\", logreg_model_28.score(XTEST, YTEST))\n",
    "\n",
    "logreg_model_29 = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('logreg', LogisticRegression(penalty='l1', solver='saga', C=0.25, max_iter=10000,random_state=rng_seed))])\n",
    "logreg_model_29.fit(XTRAIN, YTRAIN)\n",
    "#print(\"Model 29 Accuracy:\", logreg_model_29.score(XTEST, YTEST))\n",
    "\n",
    "Logistic_regression_models = [logreg_model_1,logreg_model_2,#\n",
    "                              logreg_model_3,logreg_model_4,#\n",
    "                              logreg_model_5,logreg_model_6,#\n",
    "                              logreg_model_7,logreg_model_8,#\n",
    "                              logreg_model_9,logreg_model_10,#\n",
    "                              logreg_model_11,logreg_model_12,#\n",
    "                              logreg_model_13,logreg_model_14,#\n",
    "                              logreg_model_15,logreg_model_16,#\n",
    "                              logreg_model_17,logreg_model_18,#\n",
    "                              logreg_model_19,logreg_model_20,#\n",
    "                              logreg_model_21,logreg_model_22,#\n",
    "                              logreg_model_23,logreg_model_24,#\n",
    "                              logreg_model_25,logreg_model_26,#\n",
    "                              logreg_model_27,logreg_model_28,#\n",
    "                              logreg_model_29]\n",
    "#Optimizing to find out which one is the best model\n",
    "Logistic_regression_accuracies = np.empty(len(Logistic_regression_models), dtype=float)\n",
    "for i, model_name in enumerate(Logistic_regression_models):\n",
    "  Logistic_regression_accuracies[i] = np.mean(model_name.predict(XVALID) == YVALID)\n",
    "Logistic_regression_best_accuracy = np.max(Logistic_regression_accuracies)\n",
    "Logistic_regression_best_model = Logistic_regression_models[np.argmax(Logistic_regression_accuracies)]\n",
    "\n",
    "\n",
    "\n",
    "log_reg_model_names = [f'LogReg Model {i+1}' for i in range(len(Logistic_regression_models))]\n",
    "\n",
    "\n",
    "log_reg_data =  list(zip(log_reg_model_names, Logistic_regression_accuracies))\n",
    "\n",
    "\n",
    "log_reg_headers = [\"Model Name\", \"Accuracy (%)\"]\n",
    "\n",
    "log_reg_table = tabulate(log_reg_data, headers=log_reg_headers, tablefmt=\"github\")\n",
    "print(log_reg_table)\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(16, 6))\n",
    "bars = plt.bar(log_reg_model_names, Logistic_regression_accuracies * 100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Highlight the best model in a different color\n",
    "best_idx = np.argmax(Logistic_regression_accuracies)\n",
    "bars[best_idx].set_color('orange')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Logistic Regression Models', fontsize=12)\n",
    "plt.ylabel('Validation Accuracy (%)', fontsize=12)\n",
    "plt.title('Comparison of Logistic Regression Models by Validation Accuracy', fontsize=14)\n",
    "plt.ylim(80, 90)\n",
    "\n",
    "# Annotate bars with accuracy values\n",
    "for bar, acc in zip(bars, Logistic_regression_accuracies * 100):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{acc:.2f}%', ha='center', fontsize=8,rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70455042-7eb2-4a1c-8c38-65f7ffd22107",
   "metadata": {},
   "outputs": [],
   "source": [
    "############  [RANDOM FORESTS]  #############\n",
    "\n",
    "correlation_matrix = data0.corr()\n",
    "corr_with_outcome = correlation_matrix['Diabetes_binary']\n",
    "best_features = corr_with_outcome.drop('Diabetes_binary').abs().sort_values(ascending=False).head(15).index.tolist()\n",
    "\n",
    "param_grid = {'model__penalty': ['l1', 'l2'], 'model__C': np.logspace(-3, 1, 5)}  # [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "def hypersolve(model,param_grid):\n",
    "    # 1. Create the pipeline model\n",
    "    pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', random_forest_model) ])\n",
    "\n",
    "    # 2. Construct the `GridSearchCV` object as was done in part 5.2\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        refit='accuracy' )\n",
    "\n",
    "    # 3. Run the grid search\n",
    "    gs = gs.fit(XTRAIN, YTRAIN)\n",
    "\n",
    "    # 4. Define and run `unpack_gridsearch` to obtain the results dictionary.\n",
    "    def unpack_gridsearch(gs):\n",
    "        results = pd.DataFrame(gs.cv_results_)\n",
    "        return results\n",
    "    result = unpack_gridsearch(gs)\n",
    "\n",
    "    # 5. Define and plot the result with `plot_grid_result`\n",
    "    def plot_grid_result(results, score='mean_test_score'):\n",
    "        if 'param_model__max_features' in results and 'param_model__n_estimators' in results:\n",
    "            pivot_table = results.pivot_table(\n",
    "                index='param_model__max_features',\n",
    "                columns='param_model__n_estimators',\n",
    "                values=score)\n",
    "            sns.heatmap(pivot_table, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "            plt.title(\"Grid Search Accuracy\")\n",
    "            plt.ylabel('max_features')\n",
    "            plt.xlabel('n_estimators')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Plotting not supported for this parameter grid.\")\n",
    "    plot_grid_result(result)\n",
    "\n",
    "    # 6. return result\n",
    "    return result, gs\n",
    "\n",
    "\n",
    "# Define the random forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=rng_seed)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid_rf = {\n",
    "    'model__max_features': [3,len(best_features),XTRAIN.shape[1]],\n",
    "    'model__n_estimators': np.linspace(2, 102, num=11, dtype=int)}\n",
    "\n",
    "# Run grid search using your hypersolve function\n",
    "result_rf, gs_rf = hypersolve(random_forest_model,param_grid_rf)\n",
    "\n",
    "random_forest_best_accuracy = np.mean(gs_rf.best_estimator_.predict(XVALID) == YVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673254de-31e4-4c99-b48a-93241763ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ACCURACIES ##########\n",
    "logreg_accuracy = Logistic_regression_best_accuracy\n",
    "neaural_network_accuracy = neural_network_best_accuracy\n",
    "random_forest_accuracy = random_forest_best_accuracy\n",
    "adaboost_accuracy = adaboost_best_accuracy\n",
    "\n",
    "model_accuracies = [logreg_accuracy, neaural_network_accuracy, random_forest_accuracy, adaboost_accuracy]\n",
    "model_names = ['Logistic Regression', 'Neural Network', 'Random Forest', 'AdaBoost']\n",
    "best_models = [Logistic_regression_best_model,neural_network_best_model,gs_rf,adaboost_best_model]\n",
    "\n",
    "for i in range(len(model_accuracies)):\n",
    "    print(f\"{model_names[i]} Accuracy: {model_accuracies[i]}\")\n",
    "best_accuracy = max(model_accuracies)\n",
    "best_model_index = model_accuracies.index(best_accuracy)\n",
    "print(f\"Best Model: {model_names[best_model_index]} with Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f1d99-c6a4-4e35-9102-88d63f2d693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##===== Best model run on test data =====##\n",
    "TEST_MODEL = best_models[best_model_index]\n",
    "if best_model_index == 1:\n",
    "  neural_network_test_predictions = TEST_MODEL.predict(XTEST)\n",
    "  test_outcome = np.zeros(len(neural_network_predictions), dtype=float)\n",
    "  for pred_idx in range(len(neural_network_predictions)):\n",
    "    if neural_network_predictions[pred_idx] > 0.5:\n",
    "      test_outcome[pred_idx] = 1\n",
    "    else:\n",
    "      test_outcome[pred_idx] = 0\n",
    "  TEST_MODEL_ACCURACY = np.mean(test_outcome==YVALID)\n",
    "else:\n",
    "  TEST_MODEL_ACCURACY = np.mean(TEST_MODEL.predict(XTEST) == YTEST)\n",
    "print(f'Test Accuracy: {TEST_MODEL_ACCURACY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccbce38-642b-40f3-8d13-4c9701726aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
